
import json
from backend.database.courses_db import CoursesDatabase
from backend.database.models import Course, CourseSource

# For now, we'll hardcode the path to the wiki's data file.
# In the future, this should be configurable.
WIKI_DATA_PATH = "/Users/shreyashranjan/Library/CloudStorage/OneDrive-UniversityofPittsburgh/CSC/Dev/pittcswiki/src/data/autogenerated_course_info.json"

def scrape_wiki():
    """Scrapes course information from the pittcswiki data file."""
    print("Starting wiki scrape...")

    try:
        with open(WIKI_DATA_PATH, 'r') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Wiki data file not found at {WIKI_DATA_PATH}")
        return
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from {WIKI_DATA_PATH}")
        return

    courses = data.get('courses', [])
    if not courses:
        print("No courses found in wiki data file.")
        return

    db = CoursesDatabase()
    session = db.get_session()

    for course_data in courses:
        course_code = course_data.get('id')
        if not course_code:
            continue

        # Try to find existing course to update it
        course = session.query(Course).filter_by(code=course_code).first()
        if not course:
            course = Course(code=course_code)
            session.add(course)
            print(f"Creating new course: {course_code}")
        else:
            print(f"Updating existing course: {course_code}")

        course.title = course_data.get('title')
        course.sci_href = course_data.get('sci_href')
        course.description = course_data.get('description')
        course.credits_min = course_data.get('credits')
        course.credits_max = course_data.get('credits') # Assuming min and max are the same from this source
        course.prerequisites = course_data.get('requirements')

        # Update sources
        for field in ['title', 'sci_href', 'description', 'credits_min', 'credits_max', 'prerequisites']:
            source_obj = session.query(CourseSource).filter_by(course_id=course.id, field_name=field).first()
            if not source_obj:
                source_obj = CourseSource(course_id=course.id, field_name=field, source='wiki')
                session.add(source_obj)
            else:
                source_obj.source = 'wiki'

    print(f"Processed {len(courses)} courses from the wiki.")

    session.commit()
    session.close()
    print("Wiki scrape completed and data saved to database.")

if __name__ == '__main__':
    scrape_wiki()
